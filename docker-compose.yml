services:
  vllm:
    build:
      context: .
      dockerfile: Dockerfile
    image: vllm-image-adapt:latest
    container_name: vllm-server
    ipc: host
    ports:
      - "8000:8000"
      - "8001:8001"
    environment:
      START_COMMAND: >-
        {vllm serve Qwen/Qwen3-VL-Embedding-2B --runner pooling --max-model-len 8192 --dtype auto --trust-remote-code --hf-overrides '{"matryoshka_dimensions":[1024]}' --port 8000 --gpu-memory-utilization 0.45}
        {vllm serve Qwen/Qwen3-VL-Reranker-2B --runner pooling --dtype auto --max-model-len 16384 --gpu-memory-utilization 0.48 --trust-remote-code --chat-template /app/template/qwen3_vl_reranker.jinja --port 8001 --hf-overrides '{"architectures":["Qwen3VLForSequenceClassification"],"classifier_from_token":["no","yes"],"is_original_qwen3_reranker":true}'}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
